{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d38af397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b66544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 20000    \n",
    "MAX_SEQ_LEN = 5         \n",
    "VOCAB_SIZE = 11         \n",
    "EMBED_DIM = 128\n",
    "LATENT_DIM = 256\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d40927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(num_samples=10000, max_len=7, vocab_size=11):\n",
    "    X, Y = [], []\n",
    "    for _ in range(num_samples):\n",
    "        seq_len = np.random.randint(2, max_len + 1)\n",
    "        seq = np.random.randint(1, vocab_size - 1, size=seq_len).tolist()\n",
    "        X.append(seq)\n",
    "        Y.append(seq[::-1])\n",
    "    return X, Y\n",
    "\n",
    "input_texts, target_texts = generate_data(NUM_SAMPLES, MAX_SEQ_LEN, VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "820078f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = VOCAB_SIZE - 2\n",
    "END_TOKEN = VOCAB_SIZE - 1\n",
    "\n",
    "encoder_input = tf.keras.preprocessing.sequence.pad_sequences(input_texts, maxlen=MAX_SEQ_LEN, padding='post')\n",
    "\n",
    "decoder_input = [[START_TOKEN] + seq for seq in target_texts]\n",
    "decoder_output = [seq + [END_TOKEN] for seq in target_texts]\n",
    "\n",
    "decoder_input = tf.keras.preprocessing.sequence.pad_sequences(decoder_input, maxlen=MAX_SEQ_LEN+1, padding='post')\n",
    "decoder_output = tf.keras.preprocessing.sequence.pad_sequences(decoder_output, maxlen=MAX_SEQ_LEN+1, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c384a0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ not_equal_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,827</span> │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │      \u001b[38;5;34m1,408\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │      \u001b[38;5;34m1,408\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m394,240\u001b[0m │ embedding_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ not_equal_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m394,240\u001b[0m │ embedding_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m11\u001b[0m)     │      \u001b[38;5;34m2,827\u001b[0m │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">794,123</span> (3.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m794,123\u001b[0m (3.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">794,123</span> (3.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m794,123\u001b[0m (3.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder_inputs = layers.Input(shape=(MAX_SEQ_LEN,))\n",
    "enc_emb = layers.Embedding(VOCAB_SIZE, EMBED_DIM, mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm = layers.LSTM(LATENT_DIM, return_state=True)\n",
    "_, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = layers.Input(shape=(MAX_SEQ_LEN+1,))\n",
    "dec_emb = layers.Embedding(VOCAB_SIZE, EMBED_DIM, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = layers.LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = layers.Dense(VOCAB_SIZE, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68b0ff56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 57ms/step - accuracy: 0.5845 - loss: 0.6436 - val_accuracy: 0.7587 - val_loss: 0.0360\n",
      "Epoch 2/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 56ms/step - accuracy: 0.7477 - loss: 0.0163 - val_accuracy: 0.7601 - val_loss: 0.0068\n",
      "Epoch 3/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 55ms/step - accuracy: 0.7469 - loss: 0.0107 - val_accuracy: 0.7602 - val_loss: 0.0031\n",
      "Epoch 4/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 59ms/step - accuracy: 0.7483 - loss: 0.0015 - val_accuracy: 0.7602 - val_loss: 0.0011\n",
      "Epoch 5/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 56ms/step - accuracy: 0.7483 - loss: 8.0255e-04 - val_accuracy: 0.7602 - val_loss: 7.1163e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 61ms/step - accuracy: 0.7483 - loss: 5.4062e-04 - val_accuracy: 0.7602 - val_loss: 5.2072e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 61ms/step - accuracy: 0.7483 - loss: 3.9010e-04 - val_accuracy: 0.7602 - val_loss: 3.8880e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 61ms/step - accuracy: 0.7483 - loss: 2.9452e-04 - val_accuracy: 0.7602 - val_loss: 3.0222e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 51ms/step - accuracy: 0.7483 - loss: 2.2722e-04 - val_accuracy: 0.7602 - val_loss: 2.3552e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 50ms/step - accuracy: 0.7483 - loss: 1.7989e-04 - val_accuracy: 0.7602 - val_loss: 1.8846e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 68ms/step - accuracy: 0.7483 - loss: 1.4430e-04 - val_accuracy: 0.7602 - val_loss: 1.5526e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 67ms/step - accuracy: 0.7483 - loss: 1.1661e-04 - val_accuracy: 0.7602 - val_loss: 1.2814e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 65ms/step - accuracy: 0.7483 - loss: 9.5535e-05 - val_accuracy: 0.7602 - val_loss: 1.0420e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 61ms/step - accuracy: 0.7483 - loss: 7.8693e-05 - val_accuracy: 0.7602 - val_loss: 8.7263e-05\n",
      "Epoch 15/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.7483 - loss: 6.5204e-05 - val_accuracy: 0.7602 - val_loss: 7.3581e-05\n",
      "Epoch 16/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 61ms/step - accuracy: 0.7483 - loss: 5.4504e-05 - val_accuracy: 0.7602 - val_loss: 6.1479e-05\n",
      "Epoch 17/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 72ms/step - accuracy: 0.7483 - loss: 4.5703e-05 - val_accuracy: 0.7602 - val_loss: 5.2328e-05\n",
      "Epoch 18/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step - accuracy: 0.7483 - loss: 3.8374e-05 - val_accuracy: 0.7602 - val_loss: 4.4626e-05\n",
      "Epoch 19/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 70ms/step - accuracy: 0.7483 - loss: 3.2438e-05 - val_accuracy: 0.7602 - val_loss: 3.7756e-05\n",
      "Epoch 20/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 60ms/step - accuracy: 0.7483 - loss: 2.7420e-05 - val_accuracy: 0.7602 - val_loss: 3.2499e-05\n",
      "Epoch 21/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 68ms/step - accuracy: 0.7483 - loss: 2.3336e-05 - val_accuracy: 0.7602 - val_loss: 2.8132e-05\n",
      "Epoch 22/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 67ms/step - accuracy: 0.7483 - loss: 1.9803e-05 - val_accuracy: 0.7602 - val_loss: 2.4290e-05\n",
      "Epoch 23/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 61ms/step - accuracy: 0.7483 - loss: 1.6819e-05 - val_accuracy: 0.7602 - val_loss: 2.0312e-05\n",
      "Epoch 24/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 71ms/step - accuracy: 0.7483 - loss: 1.4365e-05 - val_accuracy: 0.7602 - val_loss: 1.7973e-05\n",
      "Epoch 25/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 61ms/step - accuracy: 0.7483 - loss: 1.2298e-05 - val_accuracy: 0.7602 - val_loss: 1.5470e-05\n",
      "Epoch 26/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 0.7483 - loss: 1.0481e-05 - val_accuracy: 0.7602 - val_loss: 1.3144e-05\n",
      "Epoch 27/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - accuracy: 0.7483 - loss: 9.0049e-06 - val_accuracy: 0.7602 - val_loss: 1.1188e-05\n",
      "Epoch 28/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - accuracy: 0.7483 - loss: 7.7047e-06 - val_accuracy: 0.7602 - val_loss: 9.9835e-06\n",
      "Epoch 29/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.7483 - loss: 6.6108e-06 - val_accuracy: 0.7602 - val_loss: 8.5531e-06\n",
      "Epoch 30/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 61ms/step - accuracy: 0.7483 - loss: 5.6725e-06 - val_accuracy: 0.7602 - val_loss: 7.4118e-06\n",
      "Epoch 31/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 60ms/step - accuracy: 0.7483 - loss: 4.8583e-06 - val_accuracy: 0.7602 - val_loss: 6.7986e-06\n",
      "Epoch 32/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 59ms/step - accuracy: 0.7483 - loss: 4.1836e-06 - val_accuracy: 0.7602 - val_loss: 5.8094e-06\n",
      "Epoch 33/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 59ms/step - accuracy: 0.7483 - loss: 3.5904e-06 - val_accuracy: 0.7602 - val_loss: 5.0392e-06\n",
      "Epoch 34/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 59ms/step - accuracy: 0.7483 - loss: 3.0870e-06 - val_accuracy: 0.7602 - val_loss: 4.3042e-06\n",
      "Epoch 35/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 59ms/step - accuracy: 0.7483 - loss: 2.6669e-06 - val_accuracy: 0.7602 - val_loss: 3.6668e-06\n",
      "Epoch 36/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - accuracy: 0.7483 - loss: 2.2975e-06 - val_accuracy: 0.7602 - val_loss: 3.2917e-06\n",
      "Epoch 37/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 59ms/step - accuracy: 0.7483 - loss: 1.9748e-06 - val_accuracy: 0.7602 - val_loss: 2.7772e-06\n",
      "Epoch 38/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - accuracy: 0.7483 - loss: 1.7082e-06 - val_accuracy: 0.7602 - val_loss: 2.5807e-06\n",
      "Epoch 39/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - accuracy: 0.7483 - loss: 1.4753e-06 - val_accuracy: 0.7602 - val_loss: 2.1910e-06\n",
      "Epoch 40/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - accuracy: 0.7483 - loss: 1.2763e-06 - val_accuracy: 0.7602 - val_loss: 1.8912e-06\n",
      "Epoch 41/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 60ms/step - accuracy: 0.7483 - loss: 1.0988e-06 - val_accuracy: 0.7602 - val_loss: 1.7027e-06\n",
      "Epoch 42/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 60ms/step - accuracy: 0.7483 - loss: 9.4835e-07 - val_accuracy: 0.7602 - val_loss: 1.4881e-06\n",
      "Epoch 43/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 59ms/step - accuracy: 0.7483 - loss: 8.2132e-07 - val_accuracy: 0.7602 - val_loss: 1.2598e-06\n",
      "Epoch 44/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 59ms/step - accuracy: 0.7483 - loss: 7.0986e-07 - val_accuracy: 0.7602 - val_loss: 1.0892e-06\n",
      "Epoch 45/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 60ms/step - accuracy: 0.7483 - loss: 6.1487e-07 - val_accuracy: 0.7602 - val_loss: 9.8790e-07\n",
      "Epoch 46/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.7483 - loss: 5.3284e-07 - val_accuracy: 0.7602 - val_loss: 8.5667e-07\n",
      "Epoch 47/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.7483 - loss: 4.6137e-07 - val_accuracy: 0.7602 - val_loss: 7.7083e-07\n",
      "Epoch 48/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.7483 - loss: 3.9917e-07 - val_accuracy: 0.7602 - val_loss: 6.7229e-07\n",
      "Epoch 49/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 59ms/step - accuracy: 0.7483 - loss: 3.4849e-07 - val_accuracy: 0.7602 - val_loss: 6.1544e-07\n",
      "Epoch 50/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 71ms/step - accuracy: 0.7483 - loss: 3.0187e-07 - val_accuracy: 0.7602 - val_loss: 5.3242e-07\n",
      "Epoch 51/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 61ms/step - accuracy: 0.7483 - loss: 2.6175e-07 - val_accuracy: 0.7602 - val_loss: 4.5527e-07\n",
      "Epoch 52/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 62ms/step - accuracy: 0.7483 - loss: 2.2809e-07 - val_accuracy: 0.7602 - val_loss: 4.0752e-07\n",
      "Epoch 53/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 68ms/step - accuracy: 0.7483 - loss: 1.9939e-07 - val_accuracy: 0.7602 - val_loss: 3.7127e-07\n",
      "Epoch 54/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 0.7483 - loss: 1.7367e-07 - val_accuracy: 0.7602 - val_loss: 3.2975e-07\n",
      "Epoch 55/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 53ms/step - accuracy: 0.7483 - loss: 1.5174e-07 - val_accuracy: 0.7602 - val_loss: 2.9993e-07\n",
      "Epoch 56/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 52ms/step - accuracy: 0.7483 - loss: 1.3228e-07 - val_accuracy: 0.7602 - val_loss: 2.6951e-07\n",
      "Epoch 57/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 1.1634e-07 - val_accuracy: 0.7602 - val_loss: 2.4157e-07\n",
      "Epoch 58/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 51ms/step - accuracy: 0.7483 - loss: 1.0205e-07 - val_accuracy: 0.7602 - val_loss: 2.1920e-07\n",
      "Epoch 59/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 8.9849e-08 - val_accuracy: 0.7602 - val_loss: 1.9995e-07\n",
      "Epoch 60/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 51ms/step - accuracy: 0.7483 - loss: 7.8318e-08 - val_accuracy: 0.7602 - val_loss: 1.9762e-07\n",
      "Epoch 61/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 52ms/step - accuracy: 0.7483 - loss: 6.9347e-08 - val_accuracy: 0.7602 - val_loss: 1.4604e-07\n",
      "Epoch 62/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 6.1414e-08 - val_accuracy: 0.7602 - val_loss: 1.3933e-07\n",
      "Epoch 63/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.7483 - loss: 5.4341e-08 - val_accuracy: 0.7602 - val_loss: 1.3087e-07\n",
      "Epoch 64/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.7483 - loss: 4.8344e-08 - val_accuracy: 0.7602 - val_loss: 1.2525e-07\n",
      "Epoch 65/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 55ms/step - accuracy: 0.7483 - loss: 4.3111e-08 - val_accuracy: 0.7602 - val_loss: 1.0941e-07\n",
      "Epoch 66/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 0.7483 - loss: 3.8425e-08 - val_accuracy: 0.7602 - val_loss: 1.1234e-07\n",
      "Epoch 67/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 58ms/step - accuracy: 0.7483 - loss: 3.4322e-08 - val_accuracy: 0.7602 - val_loss: 1.0097e-07\n",
      "Epoch 68/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 61ms/step - accuracy: 0.7483 - loss: 3.0864e-08 - val_accuracy: 0.7602 - val_loss: 8.7996e-08\n",
      "Epoch 69/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.7483 - loss: 2.7851e-08 - val_accuracy: 0.7602 - val_loss: 8.7248e-08\n",
      "Epoch 70/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 66ms/step - accuracy: 0.7483 - loss: 2.5059e-08 - val_accuracy: 0.7602 - val_loss: 7.2171e-08\n",
      "Epoch 71/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 64ms/step - accuracy: 0.7483 - loss: 2.2678e-08 - val_accuracy: 0.7602 - val_loss: 7.5154e-08\n",
      "Epoch 72/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 60ms/step - accuracy: 0.7483 - loss: 2.0480e-08 - val_accuracy: 0.7602 - val_loss: 6.6785e-08\n",
      "Epoch 73/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 60ms/step - accuracy: 0.7483 - loss: 1.8870e-08 - val_accuracy: 0.7602 - val_loss: 6.9924e-08\n",
      "Epoch 74/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 51ms/step - accuracy: 0.7483 - loss: 1.7234e-08 - val_accuracy: 0.7602 - val_loss: 6.3612e-08\n",
      "Epoch 75/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 1.5780e-08 - val_accuracy: 0.7602 - val_loss: 5.6368e-08\n",
      "Epoch 76/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 1.4580e-08 - val_accuracy: 0.7602 - val_loss: 5.1843e-08\n",
      "Epoch 77/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 1.3438e-08 - val_accuracy: 0.7602 - val_loss: 5.5273e-08\n",
      "Epoch 78/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 1.2452e-08 - val_accuracy: 0.7602 - val_loss: 5.2151e-08\n",
      "Epoch 79/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 1.1695e-08 - val_accuracy: 0.7602 - val_loss: 4.6451e-08\n",
      "Epoch 80/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 1.0916e-08 - val_accuracy: 0.7602 - val_loss: 6.6766e-08\n",
      "Epoch 81/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.7483 - loss: 1.0195e-08 - val_accuracy: 0.7602 - val_loss: 5.6818e-08\n",
      "Epoch 82/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 0.7483 - loss: 9.6084e-09 - val_accuracy: 0.7602 - val_loss: 6.1317e-08\n",
      "Epoch 83/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 9.0872e-09 - val_accuracy: 0.7602 - val_loss: 4.9569e-08\n",
      "Epoch 84/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 8.6555e-09 - val_accuracy: 0.7602 - val_loss: 3.9837e-08\n",
      "Epoch 85/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.7483 - loss: 8.1630e-09 - val_accuracy: 0.7602 - val_loss: 3.9059e-08\n",
      "Epoch 86/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 7.8379e-09 - val_accuracy: 0.7602 - val_loss: 4.6252e-08\n",
      "Epoch 87/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 7.4751e-09 - val_accuracy: 0.7602 - val_loss: 5.3970e-08\n",
      "Epoch 88/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 7.0725e-09 - val_accuracy: 0.7602 - val_loss: 4.3388e-08\n",
      "Epoch 89/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 0.7483 - loss: 6.8526e-09 - val_accuracy: 0.7602 - val_loss: 3.9524e-08\n",
      "Epoch 90/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 50ms/step - accuracy: 0.7483 - loss: 6.5288e-09 - val_accuracy: 0.7602 - val_loss: 3.6616e-08\n",
      "Epoch 91/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 6.3252e-09 - val_accuracy: 0.7602 - val_loss: 5.0161e-08\n",
      "Epoch 92/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 6.1386e-09 - val_accuracy: 0.7602 - val_loss: 3.8475e-08\n",
      "Epoch 93/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 5.9099e-09 - val_accuracy: 0.7602 - val_loss: 3.9897e-08\n",
      "Epoch 94/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.7483 - loss: 5.8428e-09 - val_accuracy: 0.7602 - val_loss: 3.5541e-08\n",
      "Epoch 95/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 0.7483 - loss: 5.5850e-09 - val_accuracy: 0.7602 - val_loss: 3.8439e-08\n",
      "Epoch 96/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.7483 - loss: 5.4694e-09 - val_accuracy: 0.7602 - val_loss: 3.5112e-08\n",
      "Epoch 97/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 5.3677e-09 - val_accuracy: 0.7602 - val_loss: 3.5910e-08\n",
      "Epoch 98/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 5.1944e-09 - val_accuracy: 0.7602 - val_loss: 3.5143e-08\n",
      "Epoch 99/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 5.1148e-09 - val_accuracy: 0.7602 - val_loss: 3.4968e-08\n",
      "Epoch 100/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 4.9916e-09 - val_accuracy: 0.7602 - val_loss: 3.3244e-08\n",
      "Epoch 101/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 51ms/step - accuracy: 0.7483 - loss: 4.8934e-09 - val_accuracy: 0.7602 - val_loss: 3.8606e-08\n",
      "Epoch 102/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 4.8239e-09 - val_accuracy: 0.7602 - val_loss: 3.3606e-08\n",
      "Epoch 103/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 4.7422e-09 - val_accuracy: 0.7602 - val_loss: 3.1286e-08\n",
      "Epoch 104/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 4.6580e-09 - val_accuracy: 0.7602 - val_loss: 2.8549e-08\n",
      "Epoch 105/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 0.7483 - loss: 4.5955e-09 - val_accuracy: 0.7602 - val_loss: 3.1359e-08\n",
      "Epoch 106/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 4.5119e-09 - val_accuracy: 0.7602 - val_loss: 3.6464e-08\n",
      "Epoch 107/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 4.4818e-09 - val_accuracy: 0.7602 - val_loss: 2.7687e-08\n",
      "Epoch 108/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 4.4576e-09 - val_accuracy: 0.7602 - val_loss: 3.4692e-08\n",
      "Epoch 109/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 4.3525e-09 - val_accuracy: 0.7602 - val_loss: 3.2191e-08\n",
      "Epoch 110/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 4.4129e-09 - val_accuracy: 0.7602 - val_loss: 3.4342e-08\n",
      "Epoch 111/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.7483 - loss: 4.3094e-09 - val_accuracy: 0.7602 - val_loss: 2.8203e-08\n",
      "Epoch 112/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 4.2676e-09 - val_accuracy: 0.7602 - val_loss: 2.5948e-08\n",
      "Epoch 113/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 0.7483 - loss: 4.2395e-09 - val_accuracy: 0.7602 - val_loss: 2.9316e-08\n",
      "Epoch 114/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 4.2261e-09 - val_accuracy: 0.7602 - val_loss: 3.1203e-08\n",
      "Epoch 115/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 4.1748e-09 - val_accuracy: 0.7602 - val_loss: 2.7916e-08\n",
      "Epoch 116/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 4.1830e-09 - val_accuracy: 0.7602 - val_loss: 2.8960e-08\n",
      "Epoch 117/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 4.1270e-09 - val_accuracy: 0.7602 - val_loss: 3.1359e-08\n",
      "Epoch 118/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 56ms/step - accuracy: 0.7483 - loss: 4.1287e-09 - val_accuracy: 0.7602 - val_loss: 2.8757e-08\n",
      "Epoch 119/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 72ms/step - accuracy: 0.7483 - loss: 4.1362e-09 - val_accuracy: 0.7602 - val_loss: 2.6379e-08\n",
      "Epoch 120/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 61ms/step - accuracy: 0.7483 - loss: 4.1148e-09 - val_accuracy: 0.7602 - val_loss: 2.4235e-08\n",
      "Epoch 121/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 64ms/step - accuracy: 0.7483 - loss: 4.0924e-09 - val_accuracy: 0.7602 - val_loss: 2.4305e-08\n",
      "Epoch 122/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 56ms/step - accuracy: 0.7483 - loss: 4.0735e-09 - val_accuracy: 0.7602 - val_loss: 2.4478e-08\n",
      "Epoch 123/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 50ms/step - accuracy: 0.7483 - loss: 4.1038e-09 - val_accuracy: 0.7602 - val_loss: 3.0054e-08\n",
      "Epoch 124/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 50ms/step - accuracy: 0.7483 - loss: 4.0881e-09 - val_accuracy: 0.7602 - val_loss: 2.6408e-08\n",
      "Epoch 125/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 50ms/step - accuracy: 0.7483 - loss: 4.0694e-09 - val_accuracy: 0.7602 - val_loss: 2.6575e-08\n",
      "Epoch 126/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 0.7483 - loss: 4.1188e-09 - val_accuracy: 0.7602 - val_loss: 2.4659e-08\n",
      "Epoch 127/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 53ms/step - accuracy: 0.7483 - loss: 4.1212e-09 - val_accuracy: 0.7602 - val_loss: 2.3380e-08\n",
      "Epoch 128/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 50ms/step - accuracy: 0.7483 - loss: 4.0828e-09 - val_accuracy: 0.7602 - val_loss: 2.3447e-08\n",
      "Epoch 129/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 0.7483 - loss: 4.1239e-09 - val_accuracy: 0.7602 - val_loss: 2.3764e-08\n",
      "Epoch 130/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.7483 - loss: 4.1206e-09 - val_accuracy: 0.7602 - val_loss: 2.3629e-08\n",
      "Epoch 131/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 53ms/step - accuracy: 0.7483 - loss: 4.0929e-09 - val_accuracy: 0.7602 - val_loss: 2.3866e-08\n",
      "Epoch 132/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 52ms/step - accuracy: 0.7483 - loss: 4.1152e-09 - val_accuracy: 0.7602 - val_loss: 2.3170e-08\n",
      "Epoch 133/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 51ms/step - accuracy: 0.7483 - loss: 4.1893e-09 - val_accuracy: 0.7602 - val_loss: 2.2129e-08\n",
      "Epoch 134/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 0.7483 - loss: 4.1336e-09 - val_accuracy: 0.7602 - val_loss: 2.3757e-08\n",
      "Epoch 135/300\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 50ms/step - accuracy: 0.7483 - loss: 4.2389e-09 - val_accuracy: 0.7602 - val_loss: 2.3006e-08\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    [encoder_input, decoder_input],\n",
    "    np.expand_dims(decoder_output, -1),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74c4018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = models.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = layers.Input(shape=(LATENT_DIM,))\n",
    "decoder_state_input_c = layers.Input(shape=(LATENT_DIM,))\n",
    "dec_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_embedding_layer = layers.Embedding(VOCAB_SIZE, EMBED_DIM, mask_zero=True)\n",
    "dec_emb2 = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm_layer = decoder_lstm\n",
    "decoder_dense_layer = decoder_dense\n",
    "\n",
    "dec_outputs2, state_h2, state_c2 = decoder_lstm_layer(dec_emb2, initial_state=dec_states_inputs)\n",
    "dec_states2 = [state_h2, state_c2]\n",
    "dec_outputs2 = decoder_dense_layer(dec_outputs2)\n",
    "\n",
    "decoder_model = models.Model(\n",
    "    [decoder_inputs] + dec_states_inputs,\n",
    "    [dec_outputs2] + dec_states2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85bd1e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = START_TOKEN\n",
    "    stop_condition = False\n",
    "    decoded = []\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        if sampled_token_index == END_TOKEN or len(decoded) >= MAX_SEQ_LEN:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded.append(sampled_token_index)\n",
    "\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "457f9ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Input : [1 5 7 3 0]\n",
      "Predicted reversed: [np.int64(3), np.int64(3), np.int64(3), np.int64(3), np.int64(5)]\n"
     ]
    }
   ],
   "source": [
    "test_seq = np.array([ [1, 5, 7, 3, 0] ])\n",
    "decoded = decode_sequence(test_seq)\n",
    "print(\"Input :\", test_seq[0])\n",
    "print(\"Predicted reversed:\", decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da49a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
